# MLOps пайплайн Airflow + HDFS + FastAPI

Пет-проект, демонстрирующий полный цикл MLOps пайплайна с использованием production-стека для задач классификации. Проект построен вокруг датасета Adult Income с полной автоматизацией обучения и обслуживания моделей.

## Стек технологий

- **Apache Airflow** - оркестрация ML workflows и планирование обучения
- **HDFS** - распределенное хранение данных, моделей и артефактов
- **FastAPI** - асинхронное API для вызова ручки /predict
- **Docker** - контейнеризация и управление сервисами
- **Scikit-learn** - ML модели (Random Forest, XGBoost, Logistic Regression)

## Быстрый старт
Для работы необходим установленный Docker.

```bash
git clone <repository-url>

# Создаем .env файл с настройками
make env

# Запускаем всю инфраструктуру
make up
```
На http://localhost:8080/docs можно протестировать в SwaggerUI работу ручки /predict

На http://localhost:8081 работает AirFlow WebUI

## Схема взаимодействия сервисов
```text
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Airflow DAG   │───▶│   HDFS Storage   │◀───│   FastAPI       │
│                 │    │                  │    │                 │
│ • Загрузка      │    │ • Сырые данные   │    │ • /predict      │
│   данных        │    │ • ML модели      │    │ • Обслуживание  │
│ • Обучение      │    │ • Препроцессоры  │    │   моделей       │
│   моделей       │    │ • Метрики        │    │ • Real-time     │
│ • Валидация     │    │                  │    │   предсказания  │
│ • Сохранение    │    │                  │    │                 │
│   в HDFS        │    │                  │    │                 │
└─────────────────┘    └──────────────────┘    └─────────────────┘
```

- При запуске всех контейнеров автоматически запускается DAG, загружающий датасет AdultIncome и
обучающий на нем модели Random Forest, XGBoost, Logistic Regression. 
- Система легко масштабируется в плане добавления других моделей
- После обучения метрики и модели сохраняются в HDFS. 
- При повторном запуске контейнеров переобучения не происходит, уже готовые модели загружаются из HDFS.
- Ручка /predict позволяет выбрать используемую модель и сделать на ней предсказания

ML анализ проведен совсем простой, данный пет-проект направлен больше на инфраструктурное взаимодействие сервисов друг с другом.

## Напрашивающиеся улучшения проекта
- Мониторинг и логирование: PostgreSQL + Grafana - сбор метрик качества моделей
- Регуляризация MLOps процессов: Регулярное переобучение - DAG с расписанием для автоматического обновления моделей
- A/B тестирование - механизм постепенного rollout новых версий моделей
- Более комплексный и подробный ML анализ
